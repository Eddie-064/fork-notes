# 并发编程

- 格言一：Do not communicate by sharing memory; instead, share memory by communicating.
- 格言二：对于并发编程，我们需要构建一个新的直觉：对于并发编程的所有直觉，都是不可信的！不要相信直
  觉！

## goroutine 与 channel 通道

- 使用 `go` 命令可创建一个 goroutine，它类似一个单独的线程，独立于主 goroutine 执行
- 当 main goroutine 退出时，所有 goroutine 都将会被强制终止
- goroutines 通常使用 channel 互传数据
- channel block 可能会导致 goroutine leak，导致 OOM 内存耗尽或者程序死锁无法终止。
- 合理使用 buffered channel
- 注意并发安全问题，在循环中使用外部变量时，注意要先 copy，或者改成用 channel 接收参数
- 单向 channel，用于限制对 channel 的操作
- 应该总是由发送方关闭 channel，或者专门再设计一个观测者 goroutine 负责关闭 channel，避免 panic
- sync.WaitGroup 可用于实现观测者 goroutine 的功能，观测是否所有 channel 都已经结束。
- 通过 buffered channel 限制并发数量为 n，从而限制程序的资源用量，避免 fd 资源描述符用尽、CPU 跑满等
  问题。
  - 这被称为计数器信号量
  - 举例 `var tokens = make(chan struct{}, 20)`，channel 的值没有其他意义，一般直接使用 `struct{}`
    或者 `bool`.
- 另一个限制并发数量的方法是，只创建 n 个 goroutines 作为 worker，然后 main goroutine 往 channel 里
  发数据，再由这几个 goroutines 处理。
- 可使用 select 同时等待多个 channel，其中最先就绪的 channel 对应的 case 将被处理，其他的 case 将被
  忽略。
  - `select {}` 将永远阻塞。
  - 如果多个 case 同时就绪，select 将通过随机算法从中随机选取一个 case 进行处理。
  - 带有 `default` 的 select 语句，可实现非阻塞通讯（no blocking）

使用 channel 的 close 方法实现「取消/完成」操作的广播机制：

```go
var done_ch = make(chan struct{})

func is_done() bool {
  select {
  case <- done_ch: // done_ch 被 close，或者 done_ch 中有元素被传递
    return true
  default:
    return true
  }
}

func mark_done(){
  close(done_ch)  // 关闭 channel，表示任务已结束
}
```

## 竞争条件 race condition

竞争条件是指一类特殊的并发编程 bug.

它指的是，当一项操作并非是原子的，那在并发执行时，可能会因为执行顺序混乱，而导致无法预测的、无意义的
结果。这个结果受编译器行为、指令执行顺序、底层机器架构等许多因素的影响，难以预测与复现，是非常棘手的
一类 bug.

race condition 有如下几种类型：

- data race: 同时有多个线程并发访问同一个变量，并且其中有至少一个线程执行的是「写入」操作

这就是我们为什么需要时刻考虑并发安全问题的原因——为了避免 race condition.

### 竞争检测

为 `go build` `go run` `go test` 添加参数 `-race` 即可在运行期进行竞争检测，在发现数据竞争时，它会打
印出相关的信息。

## 并发安全

常用的 map 字典不是并发安全的，通常的解决办法有：

- 通过 channel 集中化处理对 map 的访问，使对 map 的写入操作串行化，其他 goroutine 只允许读不允许写
- 使用并发安全的字典 sync.Map，但是这会存在锁导致的性能消耗
- 手动使用 sync.Mutex 或 sync.RWMutex: 这是下策，通常性能是最差的

## sync 包

### sync.Mutex

没啥好解释的哈，就是一个很简单的锁，确保 lock 与 unlock 之间的所有的操作都是串行的。

### sync.RWMutex

sync.Mutex 的代价太高了，它使所有的操作都完全串行化。如果我们有一个变量，有许多的用户需要读它，但是
只有很少的情况下它会被修改，我们当然希望读的操作能更快些。

sync.RWMutex 就是这样一把读写锁：允许并发读取，但是只允许串行写入。

> 注意只有在有并发读取量占绝大多数，写入操作是极少数时，sync.RWMutex 才能显著提升性能。

这要求我们主动区分读取跟写入，在仅读取的时候我们要加读锁（或称**共享锁**） `mu.Rlock` 与
`mu.RUnlock`，这样并发的读取实际上会被允许。而在写入的时候我们要加写锁（或称**排他锁**） `mu.Lock`
与 `mu.Unlock`，顾名思义，这把锁是「排他」的，写入操作将完全串行化。

需要注意的是，并不是所有看起来只读的函数/方法，都可以直接加 `mu.Rlock` 锁，函数内部可能还维护了不为
人知的共享变量！「**如果有疑问，请先加排他锁**，只有确定无误时，才使用共享锁！」

### 内存同步问题

由于现代 CPU 都是多核多线程，Go 的多个 goroutine 可能分别运行在不同的 CPU 上，每个 CPU 都有自己的寄
存器与多级缓存。

这导致一个问题就是，多个 goroutine 的执行顺序是无法保证的，它们对变量的修改，也很难立即被其他
goroutine 观测到——其他 goroutine 读到的可能仍然是缓存中的过期数据！！！

一个示例如下：

```go
var x, y int
go func(){
  x = 1
  fmt.Print("y:", y, " ")
}

go func(){
  y = 1
  fmt.Print("x:", x, " ")
}
```

这个程序从理论上分析，不论两个 goroutine 的执行顺序是如何，都不应该输出如下结果：

```
# 可能性 1
x:0 y:0
# 可能性 2
y:0 x:0
```

但是由于前面提到的内存同步问题，上述两个输出是完全有可能的。

解决这个问题的方法是：

- 总是将对共享变量的读写集中在一个 goroutine 中进行，避免多个 CPU 核「分布式」读写，导致数据不一致
- 对无法集中读写的变量，使用排他锁加锁读写。

### 懒初始化 sync.Once

被 sync.Once 包裹的函数只会在第一次调用时被执行，之后就会被忽略。常用在非并发安全的初始化场景中，比
如加载数据。

sync.Once 底层是基于 mutex 锁与一个标记是否已完成初始化的 bool 值实现的。每次调用 sync.Once.Do 时，
它都会首先加锁，然后检查 bool 值确认是否已完成初始化，再决定执行指定的函数，或者是直接解锁。

### 条件变量 sync.Cond

### 原子操作

### sync.Pool 临时对象池

### sync.Map 并发安全字典

## Goroutines 与 Threads

操作系统的线程都有固定大小的栈内存，通常为 2MB，用于存储函数的局部变量，或者在调用另一个函数时，保存
当前函数的上下文。这个固定大小的栈对大多数的小 goroutines 来说太大了，非常浪费内存；而对一些复杂的、
存在非常深递归调用的 goroutines 而言这个栈又太小了。

因此 Go 在用户空间实现了 goroutines，它的栈大小是可增长的，初始的栈大小通常为 2KB，但是随着栈的使
用，最多可增长到 1GB.

### Goroutines 调度

OS Threads 由 OS 内核调度，每隔几毫秒，硬件时钟就会中断处理器，使内核函数调用调度器。这个内核函数会
首先保存当前线程的上下文，恢复另一个线程的上下文，更新内核函数自身的状态，并开始执行这个被恢复的线
程。这样一个线程切换被称为「内核上下文切换」，它的执行速度很慢，而且代价高昂。

而 Go 在用户空间实现了自己的调度器，它使用了被称为 m:n 调度的技术——在 n 个 OS threads 上运行 m 个
goroutines. Go 调度器的功能与 OS 调度器是完全一致的，区别在于它实现在用户空间，而且它只关心同一个程
序内的所有 goroutines.

Go 调度器与 OS 调度器的另一个区别在于，它不是由硬件时钟触发的中断。我们知道 Goroutines 也被许多人称
为协程、绿色线程。跟协程类似，Goroutine 也是会在获取锁时、进行 IO 操作时、访问 channel 而被 block
时、调用 time.Sleep 时，被 Go 调度器挂起，并寻找新的 goroutine 来执行.

因此 Goroutines 的设计目的是方便 IO 密集型编程，而且能方便地利用上现代多核 CPU。
