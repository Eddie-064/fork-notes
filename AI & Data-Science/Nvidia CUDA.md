# Nvidia CUDA

## K8s 中的 GPU 监控

> https://github.com/NVIDIA/dcgm-exporter

## 利用 CUDA 加速计算

> https://developer.nvidia.cn/gpu-accelerated-libraries

### 1. TensorRT

> https://developer.nvidia.cn/tensorrt

如何使用 TensorRT 加速 pytorch 的推理？

参考：

4. [Saving/Loading models compiled with Torch-TensorRT](https://pytorch.org/TensorRT/user_guide/saving_models.html)
2. [Torch-TensorRT -  Compile Stable Diffusion and Inference](https://pytorch.org/TensorRT/tutorials/_rendered_examples/dynamo/torch_compile_stable_diffusion.html)
3. [Compile a Torch Model(.pt) into Torch-TensorRT(xxx_trt.ts) via CLI](https://pytorch.org/TensorRT/cli/torchtrtc.html)

