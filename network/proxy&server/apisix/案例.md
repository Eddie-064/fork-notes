# APISIX 使用案例

## 使用 APISIX 添加 backup 服务器

即为某个 APISIX Upstream 设置一批 backup 服务器，在该服务器的默认 nodes 出错的情况下，将请求重新转发
给这批 backup 服务器进行处理。

适用场景：

- 迭代比较核心的服务时，可将旧服务设为 backup 实现流量兜底，这样在新服务处理出错的情况下，请求仍然能
  被正确处理（只是响应速度会慢一些）。

相关资料：

- https://github.com/apache/apisix/discussions/7773
- https://github.com/apache/apisix-ingress-controller/issues/935
- [proxy_next_upstream - nginx docs](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream)
  - APISIX 的 backup 逻辑是通过 nginx 实现的，因此可通过 `proxy_next_upstream` 设定触发在 backup
    nodes 上 retry 请求的条件。详见官方文档。
  - `proxy_next_upstream` 并不存在对应的 APISIX 参数，因此只能在 `nginx.conf` 里设置，这会使它在
    APISIX 全局生效。因此如果你需要设置的 retry 条件比较特殊，就不适合在共用的 APISIX 上设置这个
    retry 配置！

示例：

```shell
# 1. 创建 Upstream
#   echo-fail-500 是默认的 node，它大概率返回 5xx，以触发 backup retry 逻辑
#   echo-success-200 是 backup 服务，它只有在 backup retry 逻辑被触发，或者 echo-fail-500 健康检查失败的情况下，才会被调用
#   passive 探测：如果 echo-fail-500 连续返回了较多的 5xx，就先把它踢下线，所有流量都直接走 backup 服务
curl http://127.0.0.1:9180/apisix/admin/upstreams/test  -H 'X-API-KEY: xxx' -i -X PUT -d '
{
    "type":"roundrobin",
    "nodes": [
      { "host": "echo-fail-500.xxx.svc.cluster.local", "port": 8080, "weight": 100 },
      { "host": "echo-success-200.xxx.svc.cluster.local", "port": 8080, "weight": 0, "priority": -1 }
    ],
    "retries": 1,
    "retry_timeout": 10,
    "timeout": {
        "connect":10,
        "send":10,
        "read":10
    },
    "checks": {
        "active": {
            "timeout": 5,
            "http_path": "/health",
            "host": "foo.com",
            "healthy": {
                "interval": 2,
                "successes": 1
            },
            "unhealthy": {
                "interval": 1,
                "http_failures": 2
            },
            "req_headers": ["User-Agent: curl/7.29.0"]
        },
        "passive": {
            "healthy": {
                "http_statuses": [200, 201],
                "successes": 3
            },
            "unhealthy": {
                "http_statuses": [500, 502, 503, 504],
                "http_failures": 3,
                "tcp_failures": 3
            }
        }
    },
    "desc": "hello world",
    "scheme": "http"
}'

# 2. 创建 Service 并启用  prometheus 监控插件
#    注：prometheus 插件监控不到 retry，目前只有 access_log 能看到一个 HTTP 请求产生的所有 response_status
curl -X PUT http://localhost:9180/apisix/admin/services/test -H 'X-API-KEY: xxx' --data-raw \
'{
  "plugins": {
    "prometheus": {}
  },
  "upstream_id": "test"
}'

# 3. 创建 Route, 绑定 Service xxx
curl http://127.0.0.1:9180/apisix/admin/routes/test -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -X PUT -i -d '
{
    "uri": "/*",
    "hosts": ["foo.com", "*.bar.com"],
    "methods": ["PUT", "GET", "POST"],
    "service_id": "test"
}'
```

然后，现在就可以用工具跑点负载试试了，比如使用 k6，先编写测试脚本 `k6_test.js`：

```javascript
import { Httpx } from "https://jslib.k6.io/httpx/0.0.4/index.js"
import { sleep } from "k6"

const session = new Httpx({
  baseURL: "http://<host>:<port>", // apisix's host & port
  timeout: 2000, // 2s timeout.
})

export default function () {
  let response1 = session.get("/test", null, {
    headers: { Host: "foo.com" },
  })
  sleep(0.2)
}
```

然后开始负载测试，并观察两个 upstream nodes 实例的负载均衡状况。

```shell
k6 run k6_test.js --vus 100 --duration 5000s
```

你可以随时按 `Ctrl+C` 快捷键中断负载测试，查看测试结果。
